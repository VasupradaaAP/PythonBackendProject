# ğŸ¤– AI Document Chatbot â€“ RAG System API

A FAST API for document-based question answering using **Retrieval-Augmented Generation (RAG)**. Users can upload PDF documents and ask questions to retrieve answers.

---

## Problem Understanding & Assumptions

### ğŸ” Interpretation (Core Requirements)

The core problem is to design and implement a backend system that:

* Accepts **PDF documents** from users
* Extracts and processes document text
* Enables **question answering grounded only in uploaded documents**
* Provides **traceability** by returning retrieved context chunks and sources
* Exposes all functionality via a **clean, testable REST API**


### ğŸ¯ Use Case Chosen

**Use Case:** *AI-Powered Document Question Answering (RAG-based)*

**Example Scenario:**

* A user uploads internal PDFs (technical docs, manuals, reports)
* The user asks questions like:

  > â€œWhat is machine learning mentioned in this document?â€

* The system retrieves relevant passages and generates answers strictly from document context

This use case mirrors real-world needs in:

* Enterprise knowledge bases
* Legal / compliance document review
* Technical documentation assistants


### RAG Pipeline Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Upload â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Extraction     â”‚  PyPDF2: Extract text page-by-page
â”‚ (Page Metadata)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Text Chunking       â”‚  500 words, 50-word overlap
â”‚ (Sliding Window)    â”‚  Preserves context at boundaries
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding Generationâ”‚  sentence-transformers: all-MiniLM-L6-v2
â”‚ (384-dim vectors)   â”‚  Fast, lightweight, accurate
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS Indexing      â”‚  L2 distance, flat index
â”‚ (Vector Storage)    â”‚  ~1ms search for 10k chunks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              USER QUESTION
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Question Embedding â†’ FAISS Search   â”‚  Retrieve top-3 chunks
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Assembly    â”‚  Combine chunks with metadata
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Generation      â”‚  FLAN-T5-Base: context + question â†’ answer
â”‚ (FLAN-T5-Base)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Response + Sources  â”‚  Answer + citations + confidence
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“Œ Assumptions (Mandatory)

#### 1. Data Formats

* Only **PDF files** are supported
* PDFs are assumed to be **text-based** (not scanned images)
* Extracted text is treated as UTF-8 plain text

#### 2. External API / Model Reliability

* Embedding and LLM models run **locally**
* Models are assumed to be available at runtime via HuggingFace

#### 3. Business Logic Constraints

* Answers **must only come from retrieved document context**
* Only the **top-K most relevant chunks** are used to control hallucination

#### 4. Ambiguities & Chosen Approach

* **Ambiguity:** Should vector data be stored in the database?
* **Decision:** FAISS index is kept in memory for performance and simplicity

---

## Design Decisions

### ğŸ—„ï¸ Database Schema

#### Tables

**documents**

* Stores metadata about uploaded PDFs
* Tracks processing lifecycle (`processing`, `ready`, `failed`)

**chat_history**

* Stores every Q&A interaction
* Enables analytics, debugging, and auditability

---

### ğŸ—ï¸ Project Structure

The project follows a **Layered Architecture** with clear separation of concerns:

```
TECHIE/
â”œâ”€â”€ app.py          # API layer (FastAPI routes, middleware, handlers)
â”œâ”€â”€ ai_service.py   # RAG logic (PDF processing, embeddings, FAISS, LLM)
â”œâ”€â”€ database.py     # DB engine, session, initialization
â”œâ”€â”€ models.py       # SQLAlchemy ORM models
â”œâ”€â”€ schemas.py      # Pydantic validation schemas
â”œâ”€â”€ test_app.py     # Unit & integration tests
â”œâ”€â”€ uploads/        # Uploaded PDF storage
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

**Why this structure?**

* Easy to test each layer independently
* Business logic is isolated from HTTP concerns
* AI logic can be swapped or scaled without touching API code

---

### âœ… Validation Logic

Beyond basic type checking, the system enforces:

* **Question validation**: minimum length, no empty or whitespace-only input
* **File validation**: only `.pdf` files allowed
* **Graceful fallbacks** when no vectors or documents are available

---

### ğŸŒ External API / Model Design

Model handling follows API best practices:

* **Rate Limits**: Implicitly controlled by FastAPI and server capacity
* **Timeouts**: Long operations are isolated in service layer
* **Lazy Loading**: Models load only when first needed to reduce startup time

---

## Solution Approach (Data Flow)

### Step-by-Step Walkthrough

1. **User uploads PDF** (`POST /documents`)
2. PDF is saved to disk and metadata stored in PostgreSQL
3. Text is extracted page-by-page using PyPDF2
4. Text is chunked using a sliding window strategy
5. Embeddings are generated using SentenceTransformers
6. Vectors are indexed in FAISS
7. Document status is updated to `ready`

**Question Flow:**

1. User submits question (`POST /chat`)
2. Question embedding is generated
3. FAISS retrieves top-K similar chunks
4. Context is assembled with metadata
5. FLAN-T5 generates an answer strictly from context
6. Response, sources, confidence, and timing are returned
7. Interaction is stored in `chat_history`

---

## Error Handling Strategy

### Global Exception Handling

* FastAPI global exception handlers ensure:

  * Consistent error format
  * No stack traces leaked to users
  * Proper HTTP status codes

### Failure Scenarios Covered

| Failure              | Handling                          |
| -------------------- | --------------------------------- |
| Database unavailable | Logged + 500 response             |
| PDF parsing failure  | Document marked `failed`          |
| Model loading error  | Graceful AI error message         |
| Empty vector index   | User informed to upload documents |
| Invalid input        | 422 with validation details       |

Logging is implemented at **INFO, WARNING, and ERROR** levels for observability.

---


## ğŸ§ª Testing

### **Run All Tests**

```bash
pytest test_app.py -v
```

### **Run Specific Test Category**

```bash
# Document upload tests
pytest test_app.py -k "upload" -v

# Chat tests
pytest test_app.py -k "chat" -v

# Integration tests
pytest test_app.py -k "lifecycle" -v
```

### **Test Coverage**

The test suite includes:

**Unit Tests**:
- âœ… Input validation (Pydantic schemas)
- âœ… Database models
- âœ… RAG service

**Integration Tests**:
- âœ… POST /documents - Valid/invalid file uploads
- âœ… GET /documents - Retrieve all, with filters
- âœ… POST /chat - Question answering
- âœ… GET /chat/history - Chat history retrieval
- âœ… PUT /documents/{id} - Update metadata
- âœ… DELETE /documents/{id} - Delete and verify
- âœ… Full document lifecycle test


## How to Run the Project

### ğŸ”§ Setup Instructions

#### 1. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

#### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 3. Configure Environment Variables

Create a `.env` file based on `.env.example`:

```env
DATABASE_URL=postgresql://username:password@localhost:5432/doc_chatbot_db
```

#### 4. Run the Application

```bash
python app.py
```

---

### ğŸ“¡ API Usage Examples

#### Upload Document

```bash
curl -X POST http://localhost:8000/documents \
  -F "file=@document.pdf"
```

#### Ask Question

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"question": "What is machine learning?"}'
```

### ğŸ“¡ API Documentation

#### **Base URL**: `http://localhost:8000`

#### **1. Upload Document (POST /documents)**

Upload a PDF document for processing.

**Request**:
```bash
curl -X POST "http://localhost:8000/documents" \
  -F "file=@/path/to/document.pdf"
```

**Response** (201 Created):
```json
{
  "id": 1,
  "filename": "document.pdf",
  "file_size": 245678,
  "num_pages": 10,
  "num_chunks": 25,
  "status": "ready",
  "uploaded_at": "2026-01-06T10:30:00",
  "processed_at": "2026-01-06T10:30:15"
}
```

**Error** (422 Unprocessable Entity):
```json
{
  "detail": "Only PDF files are supported",
  "error_code": "HTTP_422"
}
```

#### **2. Get All Documents (GET /documents)**

Retrieve all uploaded documents with optional filtering.

**Request**:
```bash
# Get all documents
curl "http://localhost:8000/documents"

# With filters
curl "http://localhost:8000/documents?status_filter=ready&limit=10"
```

**Response** (200 OK):
```json
[
  {
    "id": 1,
    "filename": "ml_guide.pdf",
    "file_size": 245678,
    "num_pages": 10,
    "num_chunks": 25,
    "status": "ready",
    "uploaded_at": "2026-01-06T10:30:00",
    "processed_at": "2026-01-06T10:30:15"
  }
]
```

#### **3. Ask Question (POST /chat)**

Ask a question about uploaded documents.

**Request**:
```bash
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is machine learning?",
    "document_id": 1
  }'
```

**Response** (200 OK):
```json
{
  "question": "What is machine learning?",
  "answer": "Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed.",
  "retrieved_chunks": [
    {
      "text": "Machine learning is a method of data analysis...",
      "document_name": "ml_guide.pdf",
      "page_number": 3,
      "similarity_score": 0.92
    }
  ],
  "confidence_score": 0.89,
  "response_time": 1.25,
  "sources": ["ml_guide.pdf (Page 3)", "ml_guide.pdf (Page 5)"]
}
```

#### **4. Get Chat History (GET /chat/history)**

Retrieve past Q&A interactions.

**Request**:
```bash
# All history
curl "http://localhost:8000/chat/history"

# Filter by document
curl "http://localhost:8000/chat/history?document_id=1&limit=20"
```

**Response** (200 OK):
```json
[
  {
    "id": 1,
    "document_id": 1,
    "question": "What is machine learning?",
    "answer": "Machine learning is...",
    "confidence_score": 0.89,
    "response_time": 1.25,
    "created_at": "2026-01-06T10:35:00"
  }
]
```

#### **5. Update Document (PUT /documents/{id})**

Update document metadata.

**Request**:
```bash
curl -X PUT "http://localhost:8000/documents/1" \
  -H "Content-Type: application/json" \
  -d '{
    "filename": "updated_name.pdf",
    "status": "ready"
  }'
```

**Response** (200 OK): Updated document object
**Error** (404 Not Found):
```json
{
  "detail": "Document with ID 999 not found",
  "error_code": "HTTP_404"
}
```

#### **6. Delete Document (DELETE /documents/{id})**

Delete a document and its file.

**Request**:
```bash
curl -X DELETE "http://localhost:8000/documents/1"
```

**Response** (204 No Content): Empty response
**Error** (404 Not Found): If document doesn't exist

---

### ğŸ“˜ Interactive API Docs

* Link : `http://localhost:8000/docs`


---

